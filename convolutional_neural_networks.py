# -*- coding: utf-8 -*-
"""convolutional_neural_networks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1A-IivZBKdMf4UXIhwg7BuksHHDweqFct
"""

import numpy as np
from scipy.signal import convolve2d #convolution
from imageio import imread #read image
from sklearn.model_selection import train_test_split

import matplotlib.pyplot as plt

import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision
import torchvision.transforms as T
from torch.utils.data import Dataset,DataLoader,TensorDataset
from torchsummary import summary

"""#Convolution in numpy/scipy"""

#image
imgN = 20
image = np.random.randn(imgN,imgN) #noise

#convolution kernel
kernelN = 7
x,y = np.meshgrid(np.linspace(-3,3,kernelN),np.linspace(-3,3,kernelN))
kernel = np.exp(-(x**2 + y**2)/7) #2D - gaussian kernel

fig, ax = plt.subplots(1,2,figsize = (8,6))
ax[0].imshow(image)
ax[0].set_title("Image")
ax[1].imshow(kernel)
ax[1].set_title("Convolution Kernel")

m = image[0:3,0:3]
kernel
fm = np.dot(m,kernel) #matrix multiplication
m*kernel #elementwise product

#implementing convolution in numpy
k = imgN-kernelN +1
fm = np.zeros([k,k])

for i in range(k):
  for j in range(k):
    m = image[i:i+kernelN,j:j+kernelN]
    fm[i,j] = np.sum(m*kernel)

#convolution in scipy
fm2 = convolve2d(image,kernel,mode = 'valid')

print(fm.shape)
print(fm2.shape)

fig, ax = plt.subplots(1,4,figsize = (10,6))
ax[0].imshow(image)
ax[0].set_title("Image")
ax[1].imshow(kernel)
ax[1].set_title("Convolution Kernel")
ax[2].imshow(fm)
ax[2].set_title("Feature map (numpy)")
ax[3].imshow(fm2)
ax[3].set_title("Feature map (scipy)")

"""#Different Convolution Kernels"""

# read a pic
image1 = imread('/content/De_nieuwe_vleugel_van_het_Stedelijk_Museum_Amsterdam.jpg')
#'https://upload.wikimedia.org/wikipedia/commons/4/47/PNG_transparency_demonstration_1.png')

print("3D dimensions :",image1.shape)
plt.imshow(image1)
plt.title("Original image in 3D")

fig,ax = plt.subplots(1,3,figsize = (10,6))
ax[0].imshow(image1[:,:,0])
ax[0].set_title("Original image :RGB channel 0")
ax[1].imshow(image1[:,:,1])
ax[1].set_title("Original image :RGB channel 1")
ax[2].imshow(image1[:,:,2])
ax[2].set_title("Original image :RGB channel 2")

fig,ax = plt.subplots(1,2,figsize = (10,6))
ax[0].imshow(image1)
ax[0].set_title("Original image in 3D")

#transform image to 2D
image2 = np.mean(image1,axis = 2)
image2 = image2/np.max(image2)

print("2D dimensions :",image2.shape)

ax[1].imshow(image2)
ax[1].set_title("Transformed to 2D")

fig,ax = plt.subplots(1,3,figsize = (10,6))

#Vertical Kernel
vk = np.array([[1,0,-1],[1,0,-1],[1,0,-1]])
print(vk.shape)
ax[0].imshow(vk)
ax[0].set_title("Vertical Kernel")

#Horizontal Kernel
hk = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])
print(hk.shape)
ax[1].imshow(hk)
ax[1].set_title("Horizontal Kernel")

#Diagonal Kernel
dk = np.array([[1,0,-1],[-1,1,0],[0,-1,1]])
print(dk.shape)
ax[2].imshow(dk)
ax[2].set_title("Diagonal Kernel")

fmv = convolve2d(image2,vk,mode = "same")
fmh = convolve2d(image2,hk,mode = "same")
fmd = convolve2d(image2,dk,mode = "same")

fig,ax = plt.subplots(1,3,figsize = (10,6))
ax[0].imshow(fmv,cmap = "gray",vmin = 0,vmax = .01)
ax[0].set_title("Feature map vertical")

ax[1].imshow(fmh,cmap = "gray",vmin = 0,vmax = .01)
ax[1].set_title("Feature map horizontal")

ax[2].imshow(fmd,cmap = "gray",vmin = 0,vmax = .01)
ax[2].set_title("Feature map diagonal")

"""#Convolution in PyTorch"""

#changing to tensors and reshaping kernels
vk_t = torch.tensor(vk).view(1,1,3,3).double() #4D : (no of images in batch, channels,dim1 of image, dim2 of image)
hk_t = torch.tensor(hk).view(1,1,3,3).double() #4D
dk_t = torch.tensor(dk).view(1,1,3,3).double() #4D
image2_t = torch.tensor(image2).view(1,1,image2.shape[0],image2.shape[1]) #4D

print(vk_t.shape)
print(image2_t.shape)

cv = F.conv2d(image2_t,vk_t)
ch = F.conv2d(image2_t,hk_t)
cd = F.conv2d(image2_t,dk_t)
print(cv.shape)
print(ch.shape)
print(cd.shape)

fig,ax = plt.subplots(1,3,figsize = (10,6))
img = torch.squeeze(cv.detach()) #removes singleton dimensions
ax[0].imshow(img,cmap = "gray",vmin = 0,vmax = .01)
ax[0].set_title("Feature map vertical")

img = torch.squeeze(ch.detach())
ax[1].imshow(img,cmap = "gray",vmin = 0,vmax = .01)
ax[1].set_title("Feature map horizontal")

img = torch.squeeze(cd.detach())
ax[2].imshow(img,cmap = "gray",vmin = 0,vmax = .01)
ax[2].set_title("Feature map diagonal")

"""#Conv2 class Pytorch"""

inChans = 3 #RGB
outChans = 15 #15 feature maps aka 15 kernels
krnSize = 5 #of the 15 kernes,each kernel is 5x5
stride = 1
padding = 0

#instance of conv2d class
c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)

print(c)
print('size of weights',str(c.weight.shape))# feature maps (output channels) x input channels x kernel size
print('size of bias',str(c.bias.shape))

print("kernel 1")
print(c.weight[0,0,:,:],"\n")

print("kernel 2")
print(c.weight[0,1,:,:],"\n")

print("kernel 3")
print(c.weight[0,2,:,:])

fig,axs = plt.subplots(3,5,figsize = (8,4))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(c.weight[i,0,:,:]).detach(),cmap = "Greens")
  ax.set_title('L1(0)->L2(%s)'%i)
  ax.axis('off')

plt.tight_layout()

imsize = (1,3,64,64) #4D : (no of images in batch, RGB channels,dim1 of image (width), dim2 of image (height))
img = torch.rand(imsize)

img2view = img.permute(2,3,1,0).numpy() #pytorch wants channels first , matplotlib wants channels last
print(img.shape)
print(img2view.shape)

plt.imshow(np.squeeze(img2view))

#convolve the image with filter
convRes = c(img)
print(img.shape)
print(convRes.shape)

fig,axs = plt.subplots(3,5,figsize = (8,4))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(convRes[0,i,:,:]).detach(),cmap = "Grays")
  ax.set_title('Feature map %s'%i)
  ax.axis('off')

plt.tight_layout()

print(image1.shape)
image1_t = torch.tensor(image1).view(1,3,1675,3000).float()
print(image1_t.shape)

convRes = c(image1_t)
print(convRes.shape)

fig,axs = plt.subplots(3,5,figsize = (10,5))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(convRes[0,i,:,:]).detach(),cmap = "Grays",vmin = 0,vmax = 0.5)
  ax.set_title('Feature map %s'%i)
  ax.axis('off')

plt.tight_layout()

"""#Transpose convolution"""

inChans = 3 #RGB
outChans = 15 #15 feature maps aka 15 kernels
krnSize = 5 #of the 15 kernes,each kernel is 5x5
stride = 1
padding = 0

#instance of conv2d class
#c = nn.Conv2d(inChans,outChans,krnSize,stride,padding)
c = nn.ConvTranspose2d(inChans,outChans,krnSize,stride,padding)

print(c)
print('size of weights',str(c.weight.shape))# feature maps (output channels) x input channels x kernel size
print('size of bias',str(c.bias.shape))

fig,axs = plt.subplots(3,5,figsize = (8,4))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(c.weight[0,i,:,:]).detach(),cmap = "Greens")
  ax.set_title('L1(0)->L2(%s)'%i)
  ax.axis('off')

plt.tight_layout()

convRes = c(img)

fig,axs = plt.subplots(3,5,figsize = (10,5))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(convRes[0,i,:,:]).detach(),cmap = "Grays")
  ax.set_title('Feature map %s'%i)
  ax.axis('off')

plt.tight_layout()

convRes = c(image1_t)
print(convRes.shape)

fig,axs = plt.subplots(3,5,figsize = (10,5))

for i,ax in enumerate(axs.flatten()):
  ax.imshow(torch.squeeze(convRes[0,i,:,:]).detach(),cmap = "Grays",vmin = 0,vmax = 0.5)
  ax.set_title('Transpose conv. %s'%i)
  ax.axis('off')

plt.tight_layout()

"""#Pooling"""

#kernel or spatial extent : no. of pixels in pooling window
#stride : same as stride in convolution i.e. no. of pixels to skip in each window

#parameters
poolSize = 3
stride = 3

#instance
p2 = nn.MaxPool2d(poolSize,stride)
p3 = nn.MaxPool3d(poolSize,stride)

print(p2) #ceiling mode is False for rounding down (avoiding edges); True for rounding up (including edges)
print(p3)

#create 2D, 3D image
img2 = torch.randn(1,1,30,30)
img3 = torch.randn(1,3,30,30)

img2_p2 = p2(img2)
print(f'2D image, 2D maxpooling : {img2_p2.shape}\n')

img3_p2 = p2(img3)
print(f'3D image, 2D maxpooling : {img3_p2.shape}\n')#generates 3 channels

img3_p3 = p3(img3)
print(f'3D image, 3D maxpooling : {img3_p3.shape}\n') #generates only 1 channel

"""#Basic CNN"""

cnn0 = nn.Sequential(

    #convolution + pooling block
    nn.Conv2d(3,10,5,3,2), #inChans,outChans,krnSize,stride,padding
    nn.ReLU(), #activation function
    nn.AvgPool3d(3,3), #kernel,stride #downsampling #can be linear or non-linear

    #ANN block
    nn.Flatten(), #vectorize to make image linear
    nn.Linear(588,1),
    nn.Sigmoid()

)

print(cnn0)

img = torch.randn(1,3,128,128)
cnn0(img)

"""#CIFAR Datasets"""

cdata = torchvision.datasets.CIFAR10(root = 'cifar10',download = True)

print(cdata)

print(cdata.data.shape)
print(cdata.classes)
print(cdata.targets)
print(len(cdata.targets))

type(cdata)

cdata.data[0]

fig,axs = plt.subplots(5,5,figsize = (10,10))

for ax in axs.flatten():
  randidx = np.random.choice(len(cdata.targets))
  pic = cdata.data[randidx,:,:,:]
  label = cdata.classes[cdata.targets[randidx]]
  ax.imshow(pic)
  ax.text(16,0,label,ha = "center", color = "k",backgroundcolor = "y")
  ax.axis("off")

cdata100 = torchvision.datasets.CIFAR100(root = 'cifar100',download = True)

print(cdata100.data.shape)
print(cdata100.classes)
print(cdata100.targets)
print(len(cdata100.targets))

fig,axs = plt.subplots(5,5,figsize = (10,10))

for ax in axs.flatten():
  randidx = np.random.choice(len(cdata100.targets))
  pic = cdata100.data[randidx,:,:,:]
  label = cdata100.classes[cdata100.targets[randidx]]
  ax.imshow(pic)
  ax.text(16,0,label,ha = "center", color = "k",backgroundcolor = "y")
  ax.axis("off")

"""#Image Transforms"""

Ts = T.Compose([T.ToTensor(), #converts to tensor, normalizes data to lie between 0 to 1
                T.Resize(32*6), #increase resolution by factor of 4
                T.Grayscale(num_output_channels=1)])


cdata.transforms = Ts #include transforms in the dataset

print(cdata.data[0,:,:,:].shape) #tranformation has not been applied yet.

cdata = torchvision.datasets.CIFAR10(root = 'cifar10',download = True,transform = Ts)

#apply tranforms externally
n = 4
img1 = Ts(cdata.data[n,:,:,:])

img2 = cdata.transform(cdata.data[n,:,:,:])

fig,ax = plt.subplots(1,3,figsize = (10,3))
ax[0].imshow(cdata.data[n,:,:,:])
ax[1].imshow(torch.squeeze(img1))
ax[2].imshow(torch.squeeze(img2),cmap = "gray")

Ts2 = T.Compose([T.ToTensor(), #converts to tensor, normalizes data to lie between 0 to 1
                T.Resize(32*100) #increase resolution by factor of 4
                ])

n = 5
img1 = Ts2(cdata.data[n,:,:,:])

fig,ax = plt.subplots(1,2,figsize = (10,3))
ax[0].imshow(cdata.data[n,:,:,:])
ax[1].imshow(img1.permute(1,2,0))

data = np.loadtxt(open('/content/sample_data/mnist_train_small.csv','rb'),delimiter = ',')

#extract 8 records
labels = data[0:8,0]
data = data[0:8,1:]

#normalize
dataNorm = data/np.max(data)

#reshape to 2D
print(dataNorm.shape)
dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28)
print(dataNorm.shape)

dataT = torch.tensor(dataNorm).float()
labelsT = torch.tensor(labels).long()

??torch.utils.data.TensorDataset

class customDataset(Dataset):
  def __init__(self, tensors,transform = None):
          assert all(tensors[0].size(0) == tensor.size(0) for tensor in tensors), (
              "Size mismatch between tensors"
          )
          self.tensors = tensors
          self.transform = transform

  def __getitem__(self, index):

    if self.transform:
      x = self.transform(self.tensors[0][index])
    else:
      x = self.tensors[0][index]

    y = self.tensors[1][index]

    return x,y

  def __len__(self):
    return self.tensors[0].size(0)

#data -> custom dataset -> dataloader -> pull mini-batches -> apply transformations

imgtrans = T.Compose([
    T.ToPILImage(),
    T.RandomVerticalFlip(p=.5), # 50%probability to flip
    #T.RandomRotation(90),
    T.ToTensor()
])

train_data = customDataset((dataT,labelsT),imgtrans)
print(train_data)

train_data_loader = DataLoader(train_data,batch_size = 8,shuffle = False)

x,y = next(iter(train_data_loader))

fig,ax = plt.subplots(2,8,figsize = (16,4))

for i in range(8):
  ax[0,i].imshow(dataT[i,0,:,:].detach(),cmap = 'gray')
  ax[1,i].imshow(x[i,0,:,:].detach(),cmap = 'gray')

ax[0,0].set_ylabel("Original")
ax[1,0].set_ylabel("Transformed")

"""#CNN : classify MNIST

###Architecture

  Image (1x28x28)

  Convolution Layer #1 - 10x26x26

  Pooling Layer #1 - 10x13x13

  Convolution Layer #2 - 20x11x11

  Pooling Layer #2 - Maxpool - 20x5x5

  Fully Connected Layer #1 - 1x50

  Output Layer #1 - 1x10
"""

#CNN Layers --> Convolution Layer (learn kernels through backprop)
#CNN Layers --> Pooling Layer (reduce dimensionality, increase receptive field size)
#CNN Layers --> Fully Connected Layer (prediction - categorical or continuous)

data = np.loadtxt(open('/content/sample_data/mnist_train_small.csv','rb'),delimiter = ',')

labels = data[:,0]
data = data[:,1:]

#normalize
dataNorm = data/np.max(data)

#reshape to 2D
print(dataNorm.shape)
dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28) #no. of images x channel x width x height
print(dataNorm.shape)

#convert to tensor
dataT = torch.tensor(dataNorm).float()
labelsT = torch.tensor(labels).long()

#split the data into train and test
train_data, test_data, train_labels, test_labels = train_test_split(dataT,labelsT,test_size = 0.1)

#define tranformations
'''imgtrans = T.Compose([
  T.ToPILImage(),
  T.RandomVerticalFlip(p=.5), # 50%probability to flip
  #T.RandomRotation(90),
  T.ToTensor()
])'''

#create tensor or custom datasets
'''train_data = customDataset((dataT,labelsT),imgtrans)
print(train_data)'''

train_dataset = TensorDataset(train_data,train_labels)
test_dataset = TensorDataset(test_data,test_labels)

#DataLoader
batchsize = 32
train_loader = DataLoader(train_dataset,batch_size = batchsize , shuffle = True, drop_last = True)
test_loader = DataLoader(test_dataset,batch_size = test_dataset.tensors[0].shape[0])
print("train dataloader dimensions :",train_loader.dataset.tensors[0].shape) # no. of images x channel x width x height

def cnn_initialization_1(printtoggle = False):

  class cnn_arch_1(nn.Module):
    def __init__(self,printtoggle):
      super().__init__()

      #input 20000x1x28x28

      #convolution layer#1 10x26x26
      self.conv1 = nn.Conv2d(1,10,kernel_size = 5,stride = 1,padding = 1)#inChans,outChans,krnSize,stride,padding
      #size of output : np.floor((28+2*1-5)/1)+1 = 26
      #maxpooling layer output : 26/2 = 13
      #10x13x13

      #convolution layer#2 10x26x26
      self.conv2 = nn.Conv2d(10,20,kernel_size = 5,stride = 1,padding = 1)
      #size of output : np.floor((13 + 2*1 - 5)/1) + 1 = 11
      #maxpooling layer output : 11/2 ~ 5
      #20x5x5

      expectedSize = 20*5*5
      print("input to fc1 :",expectedSize)

      #fully connected layer
      self.fc1 = nn.Linear(expectedSize,50)

      #output  layer
      self.out = nn.Linear(50,10)

      #toggle for printing out tensor sizes during forward prop
      self.print = printtoggle

    def forward(self,x):
      def print_fun(msg,x):
        if self.print:
          print(msg,x.shape)

      print_fun("input layer: ",x)

      #convolution -> maxpooling -> relu
      x = F.relu(F.max_pool2d(self.conv1(x),kernel_size = 2))
      print_fun("cov/pool layer1: ",x)

      x = F.relu(F.max_pool2d(self.conv2(x),kernel_size = 2))
      print_fun("cov/pool layer2: ",x)

      #reshape / vectorize for linear layer
      nUnits = x.shape.numel()/x.shape[0]
      y = x

      x = x.view(-1,int(nUnits))
      print_fun("vectorize: ",x)

      #y = y.flatten() #this will not work
      #print_fun("flatten",y)

      x = F.relu(self.fc1(x))
      print_fun("fc1: ",x)

      x = self.out(x)
      print_fun("output: ",x)

      return x

  model = cnn_arch_1(printtoggle)
  lossfun = nn.CrossEntropyLoss()
  optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)

  return model,lossfun,optimizer

model,lossfun,optimizer = cnn_initialization_1(True)
x,y = next(iter(train_loader))
yhat = model(x)
print()
print("yhat shape",yhat.shape)
loss = lossfun(yhat,y)
print("Loss",loss)

summary(model,(1,28,28))

#training
def training(model,lossfun,optimizer,numepochs,train_loader,test_loader):

  #initialize losses
  losses    = torch.zeros(numepochs)
  trainAcc  = []
  testAcc   = []

  #loop over epochs
  for epochi in range(numepochs):

    #loop over training data batches

    batchAcc  = []
    batchLoss = []
    for X,y in train_loader:

      # forward pass and loss
      yHat = model(X)
      loss = lossfun(yHat,y)

      # backprop
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      #loss from this batch
      batchLoss.append(loss.item())

      #compute accuracy
      matches = torch.argmax(yHat,axis=1) == y
      matchesNumeric = matches.float()
      accuracyPct = 100*torch.mean(matchesNumeric)
      batchAcc.append( accuracyPct )


    #average training accuracy
    trainAcc.append( np.mean(batchAcc) )

    #average losses across the batches
    losses[epochi] = np.mean(batchLoss)

    #test accuracy
    model.eval()
    X,y = next(iter(test_loader)) # extract X,y from test dataloader
    with torch.no_grad(): # deactivates autograd
      yHat = model(X)

    testAcc.append( 100*torch.mean((torch.argmax(yHat,axis=1)==y).float()) )
    model.train()


  return trainAcc,testAcc,losses,model

numepochs = 10
model,lossfun,optimizer = cnn_initialization_1(False)
trainAcc,testAcc,losses,model = training(model,lossfun,optimizer,numepochs,train_loader,test_loader)

fig,ax = plt.subplots(1,2,figsize = (16,5))

ax[0].plot(losses,'s-')
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Loss")
ax[0].set_title("Model loss")

ax[1].plot(trainAcc,'s-',label = "Train")
ax[1].plot(testAcc,'o-',label = "Test")
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Accuracy")
ax[1].set_title("Accuracy")
ax[1].legend()

print("test accuracy ",testAcc[-1].item())
print("train accuracy ",round(trainAcc[-1],1))

"""#Rolled MNIST"""

data = np.loadtxt(open('/content/sample_data/mnist_train_small.csv','rb'),delimiter = ',')

labels = data[:,0]
data = data[:,1:]

#normalize
dataNorm = data/np.max(data)

#reshape to 2D
print(dataNorm.shape)
dataNorm = dataNorm.reshape(dataNorm.shape[0],1,28,28) #no. of images x channel x width x height
print(dataNorm.shape)

#convert to tensor
dataT = torch.tensor(dataNorm).float()
labelsT = torch.tensor(labels).long()

#split the data into train and test
train_data, test_data, train_labels, test_labels = train_test_split(dataT,labelsT,test_size = 0.1)

#define tranformations
'''imgtrans = T.Compose([
  T.ToPILImage(),
  T.RandomVerticalFlip(p=.5), # 50%probability to flip
  #T.RandomRotation(90),
  T.ToTensor()
])'''

#create tensor or custom datasets
'''train_data = customDataset((dataT,labelsT),imgtrans)
print(train_data)'''

train_dataset = TensorDataset(train_data,train_labels)
test_dataset = TensorDataset(test_data,test_labels)

#DataLoader
batchsize = 32
train_loader = DataLoader(train_dataset,batch_size = batchsize , shuffle = True, drop_last = True)
test_loader = DataLoader(test_dataset,batch_size = test_dataset.tensors[0].shape[0])
print("train dataloader dimensions :",train_loader.dataset.tensors[0].shape) # no. of images x channel x width x height

#randomly rolling images by 10 pixels

#training data
for i in range(train_loader.dataset.tensors[0].shape[0]):
  img = train_loader.dataset.tensors[0][i,:,:]

  randroll = np.random.randint(-10,11)
  img = torch.roll(img,randroll,dims = 1)

  train_loader.dataset.tensors[0][i,:,:] = img

#test data
for i in range(test_loader.dataset.tensors[0].shape[0]):
  img = test_loader.dataset.tensors[0][i,:,:]

  randroll = np.random.randint(-10,11)
  img = torch.roll(img,randroll,dims = 1)

  test_loader.dataset.tensors[0][i,:,:] = img

#using existing model (trained on non-shifted data)
x,y = next(iter(test_loader))
yhat = model(x)
print("Test accuracy using pretrained model and shifted test data",100*torch.mean((torch.argmax(yhat,axis=1)==y).float()))
#conclusion : test accuracy is better than when we did this with FNNs indicating the CNNs are more robut to spatial translations.
#However its still quite low and architecture needs revision for improving performance

#training model on shifted (rolled) data
numepochs = 10
model,lossfun,optimizer = cnn_initialization_1(False)
trainAcc,testAcc,losses,model = training(model,lossfun,optimizer,numepochs,train_loader,test_loader)
fig,ax = plt.subplots(1,2,figsize = (16,5))

ax[0].plot(losses,'s-')
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Loss")
ax[0].set_title("Model loss")

ax[1].plot(trainAcc,'s-',label = "Train")
ax[1].plot(testAcc,'o-',label = "Test")
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Accuracy")
ax[1].set_title("Accuracy")
ax[1].legend()

print("test accuracy ",testAcc[-1].item())
print("train accuracy ",round(trainAcc[-1],1))

"""#Modelling Gaussians

$$ f(x, y) = A \exp \left( -\frac{ (x-x_0)^2 }{2\sigma_x^2} - \frac{ (y-y_0)^2 }{2\sigma_y^2} \right) $$

$$\small\text{Architecture}$$ \\ \\ $\small\text{Image (1x91x91)}$ \\ $\small\rightarrow \text{Convolution Layer #1 - 6x91x91}$ \\ $\small\rightarrow \text{Pooling Layer #1 - 6x45x45}$ \\ $\small\rightarrow \text{Convolution Layer #2 - 4x45x45}$ \\ $\small\rightarrow \text{Pooling Layer #2 - Maxpool - 4x22x22}$ \\ $\small\rightarrow \text{Fully Connected Layer #1 - 1x50}$ \\ $\small\rightarrow \text{Output Layer - 1x1}$
"""

#create data
nPerClass = 1000
imgSize = 91

x = np.linspace(-4,4,imgSize)
x,y = np.meshgrid(x,x)

widths = [1.8,2.4] #sigma

images = torch.zeros(2*nPerClass,1,imgSize,imgSize)
labels = torch.zeros(2*nPerClass)

for i in range(2*nPerClass):
  ro = 2*np.random.randn(2) #random offset
  G = np.exp((-(x-ro[0])**2 - (y-ro[1])**2)/(2*widths[i%2]**2))

  #adding noise
  G = G + np.random.randn(imgSize,imgSize)/5

  #add to tensor
  images[i,:,:,:] = torch.tensor(G).view(1,imgSize,imgSize)
  labels[i] = i%2

labels = labels[:,None]

fig,axs = plt.subplots(3,7,figsize = (10,6))

for i,ax in enumerate(axs.flatten()):
  whichpic = np.random.randint(2*nPerClass)
  G= np.squeeze(images[whichpic,:,:])
  ax.imshow(G,vmin = -1,vmax = 1,cmap ='Blues')

#split the data into train and test
train_data, test_data, train_labels, test_labels = train_test_split(images,labels,test_size = 0.1)

#define tranformations
'''imgtrans = T.Compose([
  T.ToPILImage(),
  T.RandomVerticalFlip(p=.5), # 50%probability to flip
  #T.RandomRotation(90),
  T.ToTensor()
])'''

#create tensor or custom datasets
'''train_data = customDataset((dataT,labelsT),imgtrans)
print(train_data)'''

train_dataset = TensorDataset(train_data,train_labels)
test_dataset = TensorDataset(test_data,test_labels)

#DataLoader
batchsize = 32
train_loader = DataLoader(train_dataset,batch_size = batchsize , shuffle = True, drop_last = True)
test_loader = DataLoader(test_dataset,batch_size = test_dataset.tensors[0].shape[0])
print("train dataloader dimensions :",train_loader.dataset.tensors[0].shape) # no. of images x channel x width x height
print("test dataloader dimensions :",test_loader.dataset.tensors[0].shape) # no. of images x channel x width x height
print("train dataloader dimensions :",test_loader.dataset.tensors[1].shape) # no. of images x channel x width x height

def cnn_initialization_2():

  class cnn_arch_2(nn.Module):
    def __init__(self):
      super().__init__()

      self.enc = nn.Sequential(
          nn.Conv2d(1,6,3,padding = 1), #output size = (91 +2*1-3)/1 + 1 = 91
          nn.ReLU(),
          nn.AvgPool2d(2,2), #default value of stride is kernel size #output size = 91/2 ~ 45

          nn.Conv2d(6,4,3,padding = 1), #output size = (45 +2*1-3)/1 + 1 = 45
          nn.ReLU(),
          nn.AvgPool2d(2,2), #output size = 45/2 ~ 22

          nn.Flatten(), #vectorize conv output
          nn.Linear(22*22*4,50),
          nn.ReLU(),
          nn.Linear(50,1)

      )

    def forward(self,x):
      return self.enc(x)


  model = cnn_arch_2()
  lossfun = nn.BCEWithLogitsLoss()
  optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)

  return model,lossfun,optimizer

#test
model,lossfun,optimizer = cnn_initialization_2()

x,y = next(iter(train_loader))
yhat = model(x)
loss = lossfun(yhat,y)
print(yhat.shape)
print(loss)

summary(model,(1,91,91))

#training
def training2(model,lossfun,optimizer,numepochs,train_loader,test_loader):

  #initialize losses
  losses    = torch.zeros(numepochs)
  trainAcc  = []
  testAcc   = []

  #loop over epochs
  for epochi in range(numepochs):

    #loop over training data batches

    batchAcc  = []
    batchLoss = []
    for X,y in train_loader:

      # forward pass and loss
      yHat = model(X)
      loss = lossfun(yHat,y)

      # backprop
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      #loss from this batch
      batchLoss.append(loss.item())

      #compute accuracy
      matches = ((yHat>0).float() == y)
      matchesNumeric = matches.float()
      accuracyPct = 100*torch.mean(matchesNumeric)
      batchAcc.append( accuracyPct )


    #average training accuracy
    trainAcc.append( np.mean(batchAcc) )

    #average losses across the batches
    losses[epochi] = np.mean(batchLoss)

    #test accuracy
    model.eval()
    X,y = next(iter(test_loader)) # extract X,y from test dataloader
    with torch.no_grad(): # deactivates autograd
      yHat = model(X)

    testAcc.append( 100*torch.mean((((yHat>0).float())==y).float()) )
    model.train()


  return trainAcc,testAcc,losses,model

#model initialization
model,lossfun,optimizer = cnn_initialization_2()

#model training
numepochs = 10
trainAcc,testAcc,losses,model = training2(model,lossfun,optimizer,numepochs,train_loader,test_loader)

#visualizing results
fig,ax = plt.subplots(1,2,figsize = (16,5))

ax[0].plot(losses,'s-')
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Loss")
ax[0].set_title("Model loss")

ax[1].plot(trainAcc,'s-',label = "Train")
ax[1].plot(testAcc,'o-',label = "Test")
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Accuracy")
ax[1].set_title("Accuracy")
ax[1].legend()

print("test accuracy ",testAcc[-1].item())
print("train accuracy ",round(trainAcc[-1],1))

model.enc

print(model.enc[0])
print(model.enc[0].weight.shape)

fig,ax = plt.subplots(1,6,figsize = (10,6))

for i in range(6):
  kernel = model.enc[0].weight[i,:,:,:]
  #print(kernel)
  ax[i].imshow(torch.squeeze(kernel.detach()))

plt.suptitle("Convolution Kernels #1")

print(model.enc[3])
print(model.enc[3].weight.shape)

fig,ax = plt.subplots(1,4,figsize = (10,6))

for i in range(4):
  kernel = model.enc[3].weight[i,0,:,:]
  #print(kernel)
  ax[i].imshow(torch.squeeze(kernel.detach()))

plt.suptitle("Convolution Kernels #2")

"""#Feature maps"""

def cnn_initialization_3(printtoggle = False):

  class cnn_arch_3(nn.Module):
    def __init__(self,printtoggle):
      super().__init__()


      self.conv1 = nn.Conv2d(1,6,kernel_size = 3,stride = 1,padding = 1)#inChans,outChans,krnSize,stride,padding

      self.conv2 = nn.Conv2d(6,4,kernel_size = 3,stride = 1,padding = 1)

      expectedSize = 22*22*4

      #fully connected layer
      self.fc1 = nn.Linear(expectedSize,50)

      #output  layer
      self.out = nn.Linear(50,1)

      #toggle for printing out tensor sizes during forward prop
      self.print = printtoggle

    def forward(self,x):
      def print_fun(msg,x):
        if self.print:
          print(msg,x.shape)

      print_fun("input layer: ",x)

      conv1x = F.relu(self.conv1(x))
      x = F.avg_pool2d(conv1x,(2,2))
      print_fun("cov/pool layer1: ",x)

      conv2x = F.relu(self.conv2(x))
      x = F.avg_pool2d(conv2x,(2,2))
      print_fun("cov/pool layer2: ",x)

      #reshape / vectorize for linear layer
      x = x.reshape(x.shape[0],-1)
      print_fun("vectorize: ",x)

      x = F.relu(self.fc1(x))
      print_fun("fc1: ",x)

      x = self.out(x)
      print_fun("output: ",x)

      return x,conv1x,conv2x

  model = cnn_arch_3(printtoggle)
  lossfun = nn.BCEWithLogitsLoss()
  optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)

  return model,lossfun,optimizer

#training
def training3(model,lossfun,optimizer,numepochs,train_loader,test_loader):

  #initialize losses
  losses    = torch.zeros(numepochs)
  trainAcc  = []
  testAcc   = []

  #loop over epochs
  for epochi in range(numepochs):

    #loop over training data batches

    batchAcc  = []
    batchLoss = []
    for X,y in train_loader:

      # forward pass and loss
      yHat = model(X)[0]
      loss = lossfun(yHat,y)

      # backprop
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      #loss from this batch
      batchLoss.append(loss.item())

      #compute accuracy
      matches = ((yHat>0).float() == y)
      matchesNumeric = matches.float()
      accuracyPct = 100*torch.mean(matchesNumeric)
      batchAcc.append( accuracyPct )


    #average training accuracy
    trainAcc.append( np.mean(batchAcc) )

    #average losses across the batches
    losses[epochi] = np.mean(batchLoss)

    #test accuracy
    model.eval()
    X,y = next(iter(test_loader)) # extract X,y from test dataloader
    with torch.no_grad(): # deactivates autograd
      yHat = model(X)[0]

    testAcc.append( 100*torch.mean((((yHat>0).float())==y).float()) )
    model.train()


  return trainAcc,testAcc,losses,model

#model initialization
model,lossfun,optimizer = cnn_initialization_3(False)

#model training
numepochs = 10
trainAcc,testAcc,losses,model = training3(model,lossfun,optimizer,numepochs,train_loader,test_loader)

#visualizing results
fig,ax = plt.subplots(1,2,figsize = (16,5))

ax[0].plot(losses,'s-')
ax[0].set_xlabel("Epochs")
ax[0].set_ylabel("Loss")
ax[0].set_title("Model loss")

ax[1].plot(trainAcc,'s-',label = "Train")
ax[1].plot(testAcc,'o-',label = "Test")
ax[1].set_xlabel("Epochs")
ax[1].set_ylabel("Accuracy")
ax[1].set_title("Accuracy")
ax[1].legend()

print("test accuracy ",testAcc[-1].item())
print("train accuracy ",round(trainAcc[-1],1))

X,y = next(iter(test_loader))
yhat,conv1x,conv2x = model(X)

fig,axs = plt.subplots(2,6,figsize=(10,4))

for i in range(6):
    axs[0,i].imshow(conv1x[0,i,:,:].detach(), cmap='inferno')
    axs[0,i].set_title(f'Conv1 FM{i}')
    axs[0,i].axis('off')

for i in range(4):
    axs[1,i].imshow(conv2x[0,i,:,:].detach(), cmap='inferno')
    axs[1,i].set_title(f'Conv2 FM{i}')
    axs[1,i].axis('off')


axs[1,4].imshow(torch.squeeze(X[0,:,:].detach()), cmap='jet')
axs[1,4].set_title('Original image')
axs[1,4].axis('off')

axs[1,5].imshow(torch.squeeze(X[0,:,:].detach()), cmap='gray')
axs[1,5].set_title('Original image (gray)')
axs[1,5].axis('off')

plt.tight_layout()
plt.show()